---
title: "NEON forecast challenge - aquatics"
author: EFI RCN 2023 Ground Beetle Group
output:
  md_document: 
    variant: markdown_github
    number_sections: true
    toc: true
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# This R markdown document
Forecasting tutorial for... What is the target audience? 

To complete the workshop via this markdown document the following packages will need to be installed:

* `remotes`
* `fpp3`
* `tsibble`
* `tidyverse`
* `lubridate`
* `neon4cast` (from github)

The following code chunk should be run to install packages.

```{r eval = F}
# install.packages('remotes')
# # install.packages('fpp3') # package for applying simple forecasting methods
# install.packages('tsibble') # package for dealing with time series data sets and tsibble objects
# install.packages('tidyverse') # collection of R packages for data manipulation, analysis, and visualisation
# install.packages('lubridate') # working with dates and times
# remotes::install_github('eco4cast/neon4cast') # package from NEON4cast challenge organisers to assist with forecast building and submission
# install.packages('neonstore') # package for downloading and maintaining a local store for a NEON dataset
# install.packages('fable') # package for running forecasts
```

Additionally, R version 4.2 is required to run the neon4cast package. It's also worth checking your Rtools is up to date and compatible with R 4.2, see (https://cran.r-project.org/bin/windows/Rtools/rtools42/rtools.html). 


```{r}
version$version.string

library(tidyverse)
library(lubridate)
library(tsibble)
library(fable)
library(neon4cast)
```

If you do not wish to run the code yourself you can follow along via the html (NEON_forecast_challenge_workshop.md), which can be downloaded from the [Github repository](#add link to rendered .md document here).

# Introduction to NEON forecast challenge

The EFI RCN NEON Forecast Challenge asks the scientific community to produce ecological forecasts of future conditions at NEON sites by leveraging NEON's open data products. The Challenge is split into five themes that span aquatic and terrestrial systems, and population, community, and ecosystem processes across a broad range of ecoregions. We are excited to use this Challenge to learn more about the predictability of ecological processes by forecasting NEON data before it is collected.  
  
Which modeling frameworks, mechanistic processes, and statistical approaches best capture community, population, and ecosystem dynamics? These questions are answerable by a community generating a diverse array of forecasts. The Challenge is open to any individual or team from anywhere around the world that wants to submit forecasts. Sign up [here.](https://projects.ecoforecast.org/neon4cast-docs/Participation.html). 

## Beetles Challenge

What: 

Where: 

When: 


## Submission requirements

For the Challange, forecasts must include quantified uncertainty. The file can represent uncertainty using an ensemble forecast (multiple realizations of future conditions) or a distribution forecast (with mean and standard deviation), specified in the family and parameter columns of the forecast file. 

For an ensemble forecast, the `family` column uses the word `ensemble` to designate that it is a ensemble forecast and the parameter column is the ensemble member number (1, 2, 3 â€¦).  For a distribution forecast, the `family` column uses the word `normal` to designate a normal distribution and the parameter column must have the words mu and sigma for each forecasted variable, site_id, and datetime. For forecasts that don't have a normal distribution we recommend using the ensemble format and sampling from your non-normal distribution to generate a set of ensemble members that represents your distribution. I will go through examples of both `ensemble` and `normal` forecasts as examples. 

The full list of required columns and format can be found in the [Challenge documentation](https://projects.ecoforecast.org/neon4cast-docs/Submission-Instructions.html).

# The forecasting workflow
## Read in the data

We start forecasting by first looking at the historic data - called the 'targets'. These data are available with a latency of approximately 600 days. Here is how you read in the data from the targets file available from the EFI server. 

```{r eval=TRUE, echo = TRUE, error=FALSE, warning=FALSE, message=FALSE}
#read in the targets data
targets <- read_csv('https://data.ecoforecast.org/neon4cast-targets/beetles/beetles-targets.csv.gz')
```

Information on the NEON sites can be found on the [NEON webpage](https://www.neonscience.org/field-sites/explore-field-sites). It can be filtered to only include terrestrial sites. This table has information about the field sites, including location, ecoregion, information about the plots (e.g. elevation, mean annual precipitation and temperature, and NLCD class). 
 
```{r eval=TRUE, echo = TRUE, error=FALSE, warning=FALSE, message=FALSE}
# read in the sites data
# aquatic_sites <- read_csv("https://raw.githubusercontent.com/eco4cast/neon4cast-targets/main/NEON_Field_Site_Metadata_20220412.csv") |>
#   dplyr::filter(aquatics == 1)

neon_sites <- read_csv('https://www.neonscience.org/sites/default/files/NEON_Field_Site_Metadata_20230309.csv')
```

Let's take a look at the targets data!
```{r eval = T, echo = F}
targets[1000:1010,]

```


## Visualise the data
```{r eval = T, echo = F, warning=FALSE, fig.dim=c(10,10), fig.cap='Figure: Beetle targets data at NEON sites'}
targets %>%
  ggplot(., aes(x = datetime, y = observation, color = site_id)) +
  geom_line() +
  theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  facet_grid(variable ~ ., scales = "free_y") +
  theme(legend.position = "none")

```

We can think about what type of models might be useful to predict these variables at these sites. Below are descriptions of ?? simple models which have been constructed to get you started forecasting:

* model 1 - Null model 
* model 2 - ARIMA model
* model 3 - description... 

```{r}
#targets |> duplicates(index = datetime, key  = c(variable,site_id))

targets_ts <- targets %>%
  as_tsibble(index = datetime, key = c(variable,site_id))
```

```{r}
forecast_date <- Sys.Date() - months(12)


past <-  targets_ts |>
  filter(datetime < forecast_date)  |>
  pivot_wider(names_from="variable", values_from="observation")


future <- targets_ts |>
  filter(datetime >= forecast_date)  |>
  pivot_wider(names_from="variable", values_from="observation")
```

```{r}
## Compute a simple mean/sd model per site... obviously silly given huge seasonal aspect
null_richness <- past  %>% 
  model(null = MEAN(richness)) %>%
  forecast(h = "1 year")

null_abundance <- past  %>%
  model(null = MEAN(abundance)) %>%
  forecast(h = "1 year")
```


## Visualize the forecast

```{r}
first4 <- unique(null_richness$site_id)[1:4]

null_richness |> filter(site_id %in% first4)  |> autoplot(past) + ggtitle("richness")
null_abundance |> filter(site_id %in% first4)  |> autoplot(past) + ggtitle("abundance")
```


## Convert to EFI standard for submission
For an ensemble forecast the documentation specifies the following columns:

* `datetime`: forecast timestamp for each time step
* `reference_datetime`: The start of the forecast; this should be 0 times steps in the future. This should only be one value of reference_datetime in the file
* `site_id`: NEON code for site
* `family`: name of probability distribution that is described by the parameter values in the parameter column; only `normal` or `ensemble` are currently allowed.
* `parameter`: integer value for forecast replicate (from the `.rep` in fable output);
* `variable`: standardized variable name from the theme 
* `prediction`: forecasted value (from the `.sim` column in fable output)
* `model_id`: model name (no spaces)

We need to make sure the dataframe is in the correct format and then we can submit this to the challenge as well! This is an ensemble forecast (specified in the `family` column). 

## EFI Formatting

EFI requires a flat-file format for forecasts that avoids the use of complex list columns.  
To convey uncertainty, forecasts must be expressed either by giving mean and standard deviation (for predictions that are normally distributed) or must express forecasts as an ensemble of replicate draws from forecast distribution.
The helper function `efi_format()` handles this transformation.

```{r}
## Combine richness and abundance forecasts.
null_forecast <- bind_rows(efi_format(null_richness), 
                            efi_format(null_abundance)) 
```

Score the forecast using EFI's internal method. By default, EFI's method reports the score every unique site-time combination (unique grouping variables).
It is easy to later average across times for a by-site score.

```{r}
scores_null <- neon4cast::score(null_forecast, targets) |> filter(!is.na(observation))
# average richness scores by site
summary_scores <- scores_null |> 
  mutate(month = lubridate::month(datetime,label=TRUE)) |>
  group_by(variable,month) |>
  summarise(crps = mean(crps, na.rm=TRUE),
            logs = mean(logs, na.rm=TRUE),
            .groups = "drop") |>
  pivot_longer(c(crps, logs), names_to="metric", values_to="score")

summary_scores |>
  ggplot(aes(month, score)) + geom_col() +
  facet_grid(variable ~ metric, scales = "free_y")
```

## Submit forecast
Files need to be in the correct format for submission. The forecast organizers have created tools to help aid in the submission process. These tools can be downloaded from Github using `remotes::install_github(eco4cast/neon4cast)`.
These include functions for submitting, scoring and reading forecasts:

* `submit()` - submit the forecast file to the neon4cast server where it will be scored
* `forecast_output_validator()` - will check the file is in the correct format to be submitted
* `check_submission()` - check that your submission has been uploaded to the server

The file name needs to be in the format theme-reference_datetime-model_id
```{r eval = T}
# <<need to figure out how to edit this for beetles>>

# Start by writing the forecast to file
theme <- 'beetles'
# date <- null_forecast$datetime[1]
# forecast_name_1 <- paste0(temp_lm_forecast_EFI$model_id[1], ".csv")
# forecast_file_1 <- paste(theme, date, forecast_name_1, sep = '-')
# forecast_file_1
# 
# write_csv(null_forecast, forecast_file_1)

# neon4cast::forecast_output_validator(forecast_file_1)

```

```{r eval = FALSE}
# can uses the neon4cast::forecast_output_validator() to check the forecast is in the right format
neon4cast::submit(forecast_file = forecast_file_1,
                  ask = FALSE) # if ask = T (default), it will produce a pop-up box asking if you want to submit
```

Is the model reasonable? 







# Other things that might be useful

## How the forecasts are scored?
The Challenge implements methods from the scoringRules R package to calculate the Continuous Rank Probability Score (CRPS) via the `score4cast` package. This scores the optimum is the minimum value, so we are aiming for as small a value as possible. CRPS uses information about the variance of the forecasts as well as the estimated mean to calculate the score by comparing it with the observation. There is some balance between accuracy and precision. The forecasts will also be compared with 'null' models (RW and climatology) More info can be found in the [documentation](https://projects.ecoforecast.org/neon4cast-docs/Evaluation.html) or the `score4cast` package from EFI organizers [here](https://github.com/eco4cast/score4cast). 

You can view past submissions [here:](https://projects.ecoforecast.org/neon4cast-dashboard/aquatics.html). You can also the raw scores from the bucket directly. Have a look at the get_scores.R file.

## Other useful R packages
Check out the NEON4cast R package ([introduction](https://projects.ecoforecast.org/neon4cast-docs/Helpful-Functions.html), and [github](https://github.com/eco4cast/neon4cast)) for other helpful functions when developing your workflow for the submitting to the challenge. 

EFI has also produced a package that summarizes the proposed community standards for the common formatting and archiving of ecological forecasts. Such open standards are intended to promote interoperability and facilitate forecast adoption, distribution, validation, and synthesis ([introduction](https://projects.ecoforecast.org/neon4cast-docs/Helpful-Functions.html#efistandards-package) and [github](https://github.com/eco4cast/EFIstandards))

## Other weather variables 
You can look at what other variables are available in the NOAA weather data. There's information in the [Challenge documentation](https://projects.ecoforecast.org/neon4cast-docs/Shared-Forecast-Drivers.html) too.

```{r}
df_past %>%
  filter(site_id == 'ARIK',
         datetime > ymd('2022-01-01')) |> 
  dplyr::collect() |> 
  distinct(variable)
```

## File format
The examples shown here, submit the forecast as a _csv_ file but you can also submit your forecasts in _NetCDF_ format. See information [here](https://projects.ecoforecast.org/neon4cast-docs/Submission-Instructions.html#step-1-forecast-file-format) about the different file formats.

## Automating your forecasting workflow
Automation is a key step to producing forecasts once you have your model up and running and are happy with your forecasts. By automating your forecasting workflow, reduces the "work" needed to produce the forecasts. There are many ways to automate scripts that are written to download observations and meteorology drivers, generate forecasts, and submit forecasts. Two tools that many have used are cron jobs (see the R package cronR) that execute tasks at user specifics times and github actions. There are examples of how you might go about implementing this in the [example github repository](https://github.com/eco4cast/neon4cast-example), using github actions and binder. 

## Alternative methods to loop through each variable-site_id combination
Using the `purrr` package we can also loop through each combination of site_id and variable combination. 
This is more efficient computationally than the for loop. You need to create a dataframe with each argument as a column. Then specify this, along with the RW function as arguments in `pmap_dfr`. The `dfr` part of the function specifies that the output should be use row_bind into a dataframe. 

```{r message = F, eval = F}
site_var_combinations <- 
  # Gets every combination of site_id and variable
  expand.grid(site = unique(targets$site_id),
              var = unique(targets$variable)) %>%
  # assign the transformation depending on the variable.
  mutate(transformation = 'none') %>%
  mutate(boot_number = 200,
         h = 30,
         bootstrap = T, 
         verbose = T)

# Runs the RW forecast for each combination of variable and site_id
RW_forecasts <- purrr::pmap_dfr(site_var_combinations, RW_daily_forecast) 

```

